{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1236989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ef53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['car', 'truck', 'pedestrian', 'bicyclist', 'light']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da9ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo=cv2.dnn.readNetFromONNX(\"C:/Users/varun/OneDrive/Desktop/Yolo/model/Model4/weights/best.onnx\")\n",
    "yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176e916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('C:/Users/varun/OneDrive/Desktop/yolo/images/traffic.jpg')\n",
    "image=img.copy()\n",
    "row, col, d=image.shape\n",
    "\n",
    "max_rc=max(row,col)\n",
    "input_image=np.zeros((max_rc,max_rc,3),dtype=np.uint8)\n",
    "\n",
    "input_image[:row,:col] = image\n",
    "\n",
    "INPUT_WH_YOLO = 640 \n",
    "blob = cv2.dnn.blobFromImage(input_image,1/255,(INPUT_WH_YOLO,INPUT_WH_YOLO),swapRB=True,crop=False)\n",
    " \n",
    "yolo.setInput(blob) \n",
    "preds = yolo.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26dc23af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.59312820e+00, 5.06073189e+00, 9.35577202e+00, ...,\n",
       "         5.23483753e-02, 1.44058699e-02, 5.74992836e-01],\n",
       "        [8.48691177e+00, 4.79698181e+00, 1.69785233e+01, ...,\n",
       "         3.91665027e-02, 1.56525746e-02, 5.96078694e-01],\n",
       "        [1.72228909e+01, 3.88028908e+00, 2.25369720e+01, ...,\n",
       "         4.39776927e-02, 1.94947924e-02, 7.21913874e-01],\n",
       "        ...,\n",
       "        [5.73388916e+02, 6.12291748e+02, 1.96802750e+02, ...,\n",
       "         1.09408945e-01, 9.88907591e-02, 1.30682051e-01],\n",
       "        [5.92450562e+02, 6.09658936e+02, 1.53049301e+02, ...,\n",
       "         2.15494037e-01, 1.61423355e-01, 1.67503312e-01],\n",
       "        [6.15962585e+02, 6.10648376e+02, 1.88257919e+02, ...,\n",
       "         2.54150867e-01, 2.27203086e-01, 2.34153315e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da36be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25200, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e7c8023",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections=preds[0]\n",
    "boxes=[]\n",
    "classes = []\n",
    "confidences = []\n",
    "\n",
    "image_w,image_h=input_image.shape[:2]\n",
    "y_factor = image_h/INPUT_WH_YOLO \n",
    "x_factor = image_w/INPUT_WH_YOLO\n",
    "\n",
    "for i in range(len(detections)):\n",
    "    row = detections[i]\n",
    "    confidence = row[4]\n",
    "    if confidence > 0.4:\n",
    "        class_score = row[5:].max()\n",
    "        class_id = row[5:].argmax() \n",
    "        \n",
    "        if class_score>0.25:\n",
    "            cx,cy,w,h=row[0:4]\n",
    "        left = int((cx-0.5*w)*x_factor)\n",
    "        top = int((cy-0.5*h)*y_factor)\n",
    "        width = int(w*x_factor)\n",
    "        height = int(h*y_factor)\n",
    "        \n",
    "        box=np.array([left,top,width,height])\n",
    "        \n",
    "        confidences.append(confidence)\n",
    "        boxes.append(box)\n",
    "        classes.append(class_id)\n",
    "        \n",
    "        \n",
    "        \n",
    "boxes_np=np.array(boxes).tolist()\n",
    "confidences_np=np.array(confidences).tolist()\n",
    "\n",
    "index=cv2.dnn.NMSBoxes(boxes_np,confidences,0.25,0.45).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef2c5228",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in index:\n",
    "    x,y,w,h=boxes_np[i]\n",
    "    bb_conf=int(confidences_np[i]*100)\n",
    "    classes_id=classes[i]\n",
    "    class_name=labels[classes_id]\n",
    "    \n",
    "    text=f'{class_name}:{bb_conf}%'\n",
    "    \n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    cv2.rectangle(image,(x,y-30),(x+w,y),(255,255,255),-1)\n",
    "    \n",
    "    cv2.putText(image,text,(x,y-10),cv2.FONT_HERSHEY_PLAIN,0.7,(0,0,0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9953ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('original',img)\n",
    "cv2.imshow('yolo_prediction',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc1d723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
